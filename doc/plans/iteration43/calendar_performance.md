# Анализ производительности календаря (Iteration 43)

## Текущее состояние

- Базовая загрузка `/owner/calendar` в dev-окружении (Chrome DevTools, вкладка *Network*):
  - `chart.js` – 72.4 KB, ~41 мс  
  - `bootstrap.bundle.min.js` – 24.7 KB, ~40 мс  
  - `universal_calendar.js` – 36.3 KB, ~41 мс  
  - `plan_shift_modal.js` – 47.2 KB, ~40 мс  
  - Остальные вспомогательные бандлы (<13 KB каждый) укладываются в 25‑40 мс.
- Первичная загрузка календаря ограничена одним месяцем (по умолчанию – текущий). Дальнейшие месяцы подгружаются по мере прокрутки.  
  После фикса `processCalendarData()` и повторного вызова `renderCalendarGrid` данные за декабрь подхватываются без перезагрузки страницы.
- Запросы `/owner/calendar/api/data` и аналогичные для других ролей обслуживаются с кэшированием (`calendar_shifts:*`, `api_response:*`). Очистка выполняется после планирования/отмены смен в общих модулях планирования.

## Наблюдения

- Основные JS-бандлы вместе занимают ~260 KB. Учитывая покрытие функционала (универсальный календарь, модалка, планировщик), объём считается приемлемым.  
  Возможная оптимизация: код-сплитинг `plan_shift_modal.js` по ролям либо ленивое подключение только при первом открытии модалки.
- Динамическая подгрузка месяцев избавляет от «дыр» при скролле. Важно, чтобы после объединения данных вызывался повторный рендер (исправлено в `universal_calendar.js`).
- Кэш Redis остаётся основным «ускорителем» API. В статистике `/admin/cache/stats` полезно выделить «calendar» как отдельный тип ключей (см. TODO).

## Рекомендации

### Frontend
- Продолжить наблюдение за весом `plan_shift_modal.js`. При необходимости вынести часть вспомогательных функций (конвертация времени, форматирование) в общий слой и переиспользовать из `plan_shift.js`.
- Добавить «ленивое» подключение модалки: грузить `plan_shift_modal.js` только при первом открытии модалки, чтобы календарь без модалки загружался ещё быстрее (целевой выигрыш — 40‑50 мс и ~47 KB).

### Backend / инфраструктура
- В `/admin/cache/stats` сгруппировать ключи с префиксом `calendar_*` (timeslots, shifts, api_response) в отдельный блок, чтобы оперативно отслеживать состояние календарного кэша.
- На дашборде `/admin/monitoring` отразить ключевые Prometheus-метрики по календарю:
  - `staffprobot_http_request_duration_seconds{endpoint="/owner/calendar/api/data"}` – медиана/95‑й перцентиль.
  - `staffprobot_cache_hit_ratio` – срез до и после очисток кэша.
  - `staffprobot_db_query_duration_seconds{table="time_slots"}` – длительность тяжёлых выборок.
- Настроить алерты (Prometheus Alertmanager) при деградации:
  - время ответа API >1.5 с (95‑й перцентиль) в течение 5 минут;
  - Hit ratio кэша <60% на протяжении 15 минут.

## План изменений

### Клиент (frontend)
1. **Ленивая загрузка модалки** — перенести подключение `plan_shift_modal.js` в отложенный импорт (динамический `import()` при первом открытии); измерить выигрыш.
2. **Декомпозиция общего JS** — вынести утилиты форматирования времени в shared-модуль, чтобы уменьшить повтор в `plan_shift.js`/`plan_shift_modal.js`.
3. **UI-мониторинг** — добавить в DevTools Lighthouse сравнение до/после и зафиксировать KPI (First Contentful Paint, Time to Interactive) для страниц календаря.

### Сервер/инфраструктура
1. **/admin/cache/stats** — добавить раздел «Calendar» (префиксы `calendar_*`) с метриками hit/miss, TTL, временем последней очистки.
2. **/admin/monitoring** — вывести графики по ключевым метрикам Prometheus (см. выше) + тайлы «95-й перцентиль» и «Hit Ratio».
3. **Алерты** — настроить правила в Alertmanager для деградации API и просадок hit ratio, уведомление в Slack/Telegram.
4. **Доп. логирование** — расширить structured-логирование календарных запросов (время БД, попадание в кэш) для упрощения расследований.

## TODO

- [ ] /admin/cache/stats: вынести ключи `calendar_*` в отдельный раздел.
- [ ] /admin/monitoring: добавить виджеты/графики по метрикам календаря (см. выше).
- [ ] Ленивая загрузка `plan_shift_modal.js` (после согласования).


