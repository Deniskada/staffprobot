"""
API —Ä–æ—É—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–æ–≤
"""
import asyncio
import logging
import time
from typing import Dict, Any

from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel

from ...indexers.simple_project_indexer import SimpleProjectIndexer
from ...indexers.python_indexer import PythonIndexer
from ...indexers.markdown_indexer import MarkdownIndexer
from ...rag.engine import RAGEngine

router = APIRouter()
logger = logging.getLogger(__name__)


class IndexResponse(BaseModel):
    status: str
    project: str
    message: str


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
project_indexer = SimpleProjectIndexer()
python_indexer = PythonIndexer()
markdown_indexer = MarkdownIndexer()
rag_engine = None


async def get_rag_engine():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ RAG engine"""
    global rag_engine
    if rag_engine is None:
        rag_engine = RAGEngine()
        await rag_engine.initialize()
    return rag_engine


async def index_project_background(project_name: str):
    """–§–æ–Ω–æ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)"""
    try:
        logger.info(f"=== –ù–∞—á–∞–ª–æ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {project_name} ===")
        start_time = time.time()

        # –ü–æ–ª—É—á–µ–Ω–∏–µ RAG engine
        rag = await get_rag_engine()

        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–∂–µ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        # –í–ê–ñ–ù–û: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º collection.get() - —ç—Ç–æ –º–µ–¥–ª–µ–Ω–Ω–æ –∏ –≤–∏—Å–Ω–µ—Ç
        # –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø—Ä–æ—Å—Ç–æ –ø—ã—Ç–∞–µ–º—Å—è –¥–æ–±–∞–≤–∏—Ç—å, ChromaDB —Å–∞–º –æ—Ç–±—Ä–æ—Å–∏—Ç –¥—É–±–ª–∏ –ø–æ ID
        indexed_files = set()  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º - –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞—Ä–∞–Ω–µ–µ
        logger.info(
            "üìä –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –±–µ–∑ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (–¥—É–±–ª–∏ –æ—Ç–±—Ä–æ—Å–∏—Ç ChromaDB)"
        )

        stats = {
            "total_files": 0,
            "python_files": 0,
            "markdown_files": 0,
            "total_chunks": 0,
            "errors": 0,
        }

        # –ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
        logger.info(f"üöÄ –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ {project_name}")
        async for file_info in project_indexer.iter_project_files(project_name):
            try:
                file_path = file_info["file_path"]
                file_type = file_info["file_type"]
                relative_path = file_info["relative_path"]

                stats["total_files"] += 1

                # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞
                chunks = []
                if file_type == "python":
                    chunks = await python_indexer.index_file(file_path)
                    stats["python_files"] += 1
                elif file_type == "markdown":
                    chunks = await markdown_indexer.index_file(file_path)
                    stats["markdown_files"] += 1

                # –ó–∞–≥—Ä—É–∑–∫–∞ —á–∞–Ω–∫–æ–≤ –≤ ChromaDB
                for chunk in chunks:
                    try:
                        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                        doc_type = (
                            python_indexer._classify_doc_type(relative_path)
                            if file_type == "python"
                            else "documentation"
                        )

                        await rag.store_document(
                            project=project_name,
                            content=chunk["content"],
                            metadata={
                                "file": relative_path,
                                "type": chunk["type"],
                                "doc_type": doc_type,
                                "start_line": chunk.get("start_line", 0),
                                "end_line": chunk.get("end_line", 0),
                                "lines": chunk.get(
                                    "lines",
                                    f"{chunk.get('start_line', 0)}-{chunk.get('end_line', 0)}",
                                ),
                                "project": project_name,
                                "chunk_id": chunk.get(
                                    "chunk_id", hash(chunk["content"][:100])
                                ),
                            },
                        )
                        stats["total_chunks"] += 1
                    except Exception as error:
                        stats["errors"] += 1
                        logger.error("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —á–∞–Ω–∫–∞: %s", error)

                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if stats["total_files"] % 50 == 0:
                    logger.info(
                        "üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: %s —Ñ–∞–π–ª–æ–≤, %s —á–∞–Ω–∫–æ–≤, %s –æ—à–∏–±–æ–∫",
                        stats["total_files"],
                        stats["total_chunks"],
                        stats["errors"],
                    )

            except Exception as error:
                stats["errors"] += 1
                logger.error(
                    "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ %s: %s",
                    file_info.get("relative_path", "unknown"),
                    error,
                )

        processing_time = time.time() - start_time

        logger.info(f"=== –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {processing_time:.2f}—Å ===")
        logger.info(
            "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: —Ñ–∞–π–ª–æ–≤=%s, —á–∞–Ω–∫–æ–≤=%s, –æ—à–∏–±–æ–∫=%s",
            stats["total_files"],
            stats["total_chunks"],
            stats["errors"],
        )

    except Exception as error:
        logger.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: %s", error, exc_info=True)


@router.post("/index/{project_name}", response_model=IndexResponse)
async def index_project(project_name: str, background_tasks: BackgroundTasks):
    """
    –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –ø—Ä–æ–µ–∫—Ç —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        project_indexer.load_config()
        project_names = [p["name"] for p in project_indexer.projects]

        if project_name not in project_names:
            raise HTTPException(
                status_code=404,
                detail=f"–ü—Ä–æ–µ–∫—Ç {project_name} –Ω–µ –Ω–∞–π–¥–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {project_names}",
            )

        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–∏
        background_tasks.add_task(index_project_background, project_name)

        return IndexResponse(
            status="started",
            project=project_name,
            message=(
                f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞ {project_name} –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ. "
                "–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ –ª–æ–≥–∏ Docker."
            ),
        )

    except HTTPException:
        raise
    except Exception as error:
        logger.error("–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: %s", error)
        raise HTTPException(status_code=500, detail=str(error))


@router.get("/index/status/{project_name}")
async def get_index_status(project_name: str):
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
    """
    try:
        rag = await get_rag_engine()

        collection = rag.get_collection(project_name)
        count = await asyncio.to_thread(collection.count)

        return {
            "project": project_name,
            "total_documents": count,
            "status": "indexed" if count > 0 else "empty",
            "message": f"–í –±–∞–∑–µ {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
        }

    except Exception as error:
        logger.error("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: %s", error)
        raise HTTPException(status_code=500, detail=str(error))
